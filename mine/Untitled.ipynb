{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1', u'12', u'814', u'UA', u'134', u'0', u'0', u'679']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "can_flight=sc.textFile('CancelledFlights.csv')\n",
    "can_flight=can_flight.map(lambda a:a.split(','))\n",
    "#First Row\n",
    "can_flight.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exploring Unique Carrier distinct names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'AA', u'DL', u'UA']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can_flight.map(lambda a:a[3]).distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.describe of DataFrame[_1: string, _2: string, _3: string, _4: string, _5: string, _6: string, _7: string, _8: string]>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can_flight.toDF().describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transforming categorical to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preProc(x):\n",
    "    dic={'AA':0,'DL':1,'UA':2}\n",
    "    return map(lambda a:float(a),x[0:3]+x[4:]+[dic[x[3]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proc_data=can_flight.map(preProc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 12.0, 814.0, 134.0, 0.0, 0.0, 679.0, 2.0],\n",
       " [1.0, 12.0, 830.0, 90.0, 0.0, 0.0, 214.0, 1.0],\n",
       " [1.0, 1.0, 1835.0, 213.0, 0.0, 0.0, 1605.0, 2.0]]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_data.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transforming rows to LabeledPoints. LabeledPoints is a data structure in Spark which contains of (label, feature) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(1.0, [12.0,814.0,134.0,0.0,0.0,679.0,2.0]),\n",
       " LabeledPoint(1.0, [12.0,830.0,90.0,0.0,0.0,214.0,1.0])]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.classification import LabeledPoint\n",
    "proc_data=proc_data.map(lambda a:LabeledPoint(a[0],a[1:]))\n",
    "proc_data.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Splitting the data into training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights=[0.9,.05,.05]\n",
    "seed=1992\n",
    "train, validation, test = proc_data.randomSplit(weights,seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import SVMWithSGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.842465753425\n",
      "Validation Error = 0.157534246575\n",
      "Accuracy of Canceled Predictions 0.0\n",
      "Accuracy of Not Canceled Predictions 1.0\n"
     ]
    }
   ],
   "source": [
    "svmFit=SVMWithSGD()\n",
    "svmModel=svmFit.train(train)\n",
    "svmLabelsAndPredsTrain = validation.map(lambda p: (p.label, svmModel.predict(p.features)))\n",
    "#Overall True Prediction Rate\n",
    "#print svmLabelsAndPredsTrain.filter(lambda (a,b):a==b).count()/float(validation.count())\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "testErr = svmLabelsAndPredsTrain.filter(lambda (v, p): v != p).count() / float(validation.count())\n",
    "print('Validation Accuracy = ' + str(testErr))\n",
    "print 'Accuracy of Canceled Predictions',svmLabelsAndPredsTrain.filter(lambda (a,b):a==1).filter(lambda (a,b):a==b).count()/float(svmLabelsAndPredsTrain.filter(lambda (a,b):a==1).count())\n",
    "print 'Accuracy of Not Canceled Predictions',svmLabelsAndPredsTrain.filter(lambda (a,b):a==0).filter(lambda (a,b):a==b).count()/float(svmLabelsAndPredsTrain.filter(lambda (a,b):a==0).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy for prediction cancellations is 0, for SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest with tree size 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Error = 0.00684931506849\n",
      "Accuracy of Canceled Predictions 1.0\n",
      "Accuracy of Not Canceled Predictions 0.991869918699\n"
     ]
    }
   ],
   "source": [
    "rfFit=RandomForest\n",
    "rfModel=rfFit.trainClassifier(train,numClasses=2,categoricalFeaturesInfo={},numTrees=10)\n",
    "#svmLabelsAndPredsTrain = validation.map(lambda p: (p.label, rfModel.predict(p.features)))\n",
    "#print svmLabelsAndPredsTrain.filter(lambda (a,b):a==b).count()/float(validation.count())\n",
    "predictions = rfModel.predict(validation.map(lambda x: x.features))\n",
    "labelsAndPredictions = validation.map(lambda lp: lp.label).zip(predictions)\n",
    "testErr = labelsAndPredictions.filter(lambda (v, p): v != p).count() / float(validation.count())\n",
    "print('Validation Error = ' + str(testErr))\n",
    "print 'Accuracy of Canceled Predictions',labelsAndPredictions.filter(lambda (a,b):a==1).filter(lambda (a,b):a==b).count()/float(labelsAndPredictions.filter(lambda (a,b):a==1).count())\n",
    "print 'Accuracy of Not Canceled Predictions',labelsAndPredictions.filter(lambda (a,b):a==0).filter(lambda (a,b):a==b).count()/float(labelsAndPredictions.filter(lambda (a,b):a==0).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest with tree size 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Error = 0.00342465753425\n",
      "Accuracy of Canceled Predictions 1.0\n",
      "Accuracy of Not Canceled Predictions 0.99593495935\n"
     ]
    }
   ],
   "source": [
    "rfFit=RandomForest\n",
    "rfModel=rfFit.trainClassifier(train,numClasses=2,categoricalFeaturesInfo={},numTrees=50)\n",
    "#svmLabelsAndPredsTrain = validation.map(lambda p: (p.label, rfModel.predict(p.features)))\n",
    "#print svmLabelsAndPredsTrain.filter(lambda (a,b):a==b).count()/float(validation.count())\n",
    "predictions = rfModel.predict(validation.map(lambda x: x.features))\n",
    "labelsAndPredictions = validation.map(lambda lp: lp.label).zip(predictions)\n",
    "testErr = labelsAndPredictions.filter(lambda (v, p): v != p).count() / float(validation.count())\n",
    "print('Validation Error = ' + str(testErr))\n",
    "\n",
    "print 'Accuracy of Canceled Predictions',labelsAndPredictions.filter(lambda (a,b):a==1).filter(lambda (a,b):a==b).count()/float(labelsAndPredictions.filter(lambda (a,b):a==1).count())\n",
    "print 'Accuracy of Not Canceled Predictions',labelsAndPredictions.filter(lambda (a,b):a==0).filter(lambda (a,b):a==b).count()/float(labelsAndPredictions.filter(lambda (a,b):a==0).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest with tree size 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Error = 0.00342465753425\n",
      "Accuracy of Canceled Predictions 1.0\n",
      "Accuracy of Not Canceled Predictions 0.99593495935\n"
     ]
    }
   ],
   "source": [
    "rfFit=RandomForest\n",
    "rfModel=rfFit.trainClassifier(train,numClasses=2,categoricalFeaturesInfo={},numTrees=200)\n",
    "#svmLabelsAndPredsTrain = validation.map(lambda p: (p.label, rfModel.predict(p.features)))\n",
    "#print svmLabelsAndPredsTrain.filter(lambda (a,b):a==b).count()/float(validation.count())\n",
    "predictions = rfModel.predict(validation.map(lambda x: x.features))\n",
    "labelsAndPredictions = validation.map(lambda lp: lp.label).zip(predictions)\n",
    "testErr = labelsAndPredictions.filter(lambda (v, p): v != p).count() / float(validation.count())\n",
    "print('Validation Error = ' + str(testErr))\n",
    "\n",
    "print 'Accuracy of Canceled Predictions',labelsAndPredictions.filter(lambda (a,b):a==1).filter(lambda (a,b):a==b).count()/float(labelsAndPredictions.filter(lambda (a,b):a==1).count())\n",
    "print 'Accuracy of Not Canceled Predictions',labelsAndPredictions.filter(lambda (a,b):a==0).filter(lambda (a,b):a==b).count()/float(labelsAndPredictions.filter(lambda (a,b):a==0).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From results of Random Forest, we can see that the accuracy achieved when tree size is 50 is greater than that when tree size is 10 and equal to the accuracy achieved when tree size is 200. Therefore, we perform our final prediction using Random Forest with 50 number of trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Final Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfFit=RandomForest\n",
    "rfModel=rfFit.trainClassifier(train,numClasses=2,categoricalFeaturesInfo={},numTrees=50)\n",
    "predictions = rfModel.predict(test.map(lambda x: x.features))\n",
    "labelsAndPredictions = test.map(lambda lp: lp.label).zip(predictions)\n",
    "testErr = labelsAndPredictions.filter(lambda (v, p): v != p).count() / float(test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Testing Error = 0.0034965034965\n",
      "Accuracy of Canceled Predictions 1.0\n",
      "Accuracy of Not Canceled Predictions 0.995762711864\n"
     ]
    }
   ],
   "source": [
    "print('Final Testing Error = ' + str(testErr))\n",
    "print 'Accuracy of Canceled Predictions',labelsAndPredictions.filter(lambda (a,b):a==1).filter(lambda (a,b):a==b).count()/float(labelsAndPredictions.filter(lambda (a,b):a==1).count())\n",
    "print 'Accuracy of Not Canceled Predictions',labelsAndPredictions.filter(lambda (a,b):a==0).filter(lambda (a,b):a==b).count()/float(labelsAndPredictions.filter(lambda (a,b):a==0).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Misclassified Labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 1.0)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelsAndPredictions.filter(lambda (a,b):a==0).filter(lambda (a,b):a!=b).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One label, which is not cancelled is predicted as cancelled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We get almost 100% testing accuracy with Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
